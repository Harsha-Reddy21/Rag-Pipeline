{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a9050c2-6f4c-41ca-bf2f-4560d37925d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-5.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.7.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting spacy\n",
      "  Using cached spacy-3.8.7-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.3.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting faiss-cpu\n",
      "  Using cached faiss_cpu-1.11.0-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting PyMuPDF\n",
      "  Using cached pymupdf-1.26.3-cp39-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting python-docx\n",
      "  Using cached python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Using cached transformers-4.53.1-py3-none-any.whl.metadata (40 kB)\n",
      "Collecting tqdm (from sentence-transformers)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Using cached torch-2.7.1-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Using cached scipy-1.16.0-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Using cached huggingface_hub-0.33.2-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting Pillow (from sentence-transformers)\n",
      "  Using cached pillow-11.3.0-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\misogi\\day18\\rag-pipeline\\legal-document\\myenv\\lib\\site-packages (from sentence-transformers) (4.14.1)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Using cached spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Using cached murmurhash-1.0.13-cp312-cp312-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Using cached cymem-2.0.11-cp312-cp312-win_amd64.whl.metadata (8.8 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Using cached preshed-3.0.10-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Using cached thinc-8.3.6-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Using cached wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Using cached srsly-2.5.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Using cached weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
      "  Using cached typer-0.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\misogi\\day18\\rag-pipeline\\legal-document\\myenv\\lib\\site-packages (from spacy) (2.32.4)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy)\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\misogi\\day18\\rag-pipeline\\legal-document\\myenv\\lib\\site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\misogi\\day18\\rag-pipeline\\legal-document\\myenv\\lib\\site-packages (from spacy) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\misogi\\day18\\rag-pipeline\\legal-document\\myenv\\lib\\site-packages (from spacy) (25.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Using cached langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting lxml>=3.1.0 (from python-docx)\n",
      "  Using cached lxml-6.0.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting filelock (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\misogi\\day18\\rag-pipeline\\legal-document\\myenv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Using cached language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Using cached pydantic_core-2.33.2-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\misogi\\day18\\rag-pipeline\\legal-document\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\misogi\\day18\\rag-pipeline\\legal-document\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\misogi\\day18\\rag-pipeline\\legal-document\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\misogi\\day18\\rag-pipeline\\legal-document\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.6.15)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Using cached blis-1.3.0-cp312-cp312-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Using cached confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\misogi\\day18\\rag-pipeline\\legal-document\\myenv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached tokenizers-0.21.2-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting click>=8.0.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Using cached cloudpathlib-0.21.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading smart_open-7.3.0.post1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\misogi\\day18\\rag-pipeline\\legal-document\\myenv\\lib\\site-packages (from jinja2->spacy) (3.0.2)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Using cached marisa_trie-1.2.1-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\misogi\\day18\\rag-pipeline\\legal-document\\myenv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
      "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Using cached wrapt-1.17.2-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Using cached sentence_transformers-5.0.0-py3-none-any.whl (470 kB)\n",
      "Using cached scikit_learn-1.7.0-cp312-cp312-win_amd64.whl (10.7 MB)\n",
      "Using cached spacy-3.8.7-cp312-cp312-win_amd64.whl (13.9 MB)\n",
      "Using cached numpy-2.3.1-cp312-cp312-win_amd64.whl (12.7 MB)\n",
      "Using cached faiss_cpu-1.11.0-cp312-cp312-win_amd64.whl (15.0 MB)\n",
      "Using cached pymupdf-1.26.3-cp39-abi3-win_amd64.whl (18.7 MB)\n",
      "Using cached python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
      "Using cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Using cached cymem-2.0.11-cp312-cp312-win_amd64.whl (39 kB)\n",
      "Using cached huggingface_hub-0.33.2-py3-none-any.whl (515 kB)\n",
      "Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Using cached langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Using cached lxml-6.0.0-cp312-cp312-win_amd64.whl (4.0 MB)\n",
      "Using cached murmurhash-1.0.13-cp312-cp312-win_amd64.whl (24 kB)\n",
      "Using cached preshed-3.0.10-cp312-cp312-win_amd64.whl (116 kB)\n",
      "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "Using cached scipy-1.16.0-cp312-cp312-win_amd64.whl (38.4 MB)\n",
      "Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Using cached srsly-2.5.1-cp312-cp312-win_amd64.whl (632 kB)\n",
      "Using cached thinc-8.3.6-cp312-cp312-win_amd64.whl (1.7 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached torch-2.7.1-cp312-cp312-win_amd64.whl (216.1 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached transformers-4.53.1-py3-none-any.whl (10.8 MB)\n",
      "Using cached typer-0.16.0-py3-none-any.whl (46 kB)\n",
      "Using cached wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Using cached weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Using cached pillow-11.3.0-cp312-cp312-win_amd64.whl (7.0 MB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached blis-1.3.0-cp312-cp312-win_amd64.whl (6.3 MB)\n",
      "Using cached click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Using cached cloudpathlib-0.21.1-py3-none-any.whl (52 kB)\n",
      "Using cached confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Using cached fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "Using cached language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "Using cached regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "Using cached rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading smart_open-7.3.0.post1-py3-none-any.whl (61 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached tokenizers-0.21.2-cp39-abi3-win_amd64.whl (2.5 MB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "Using cached marisa_trie-1.2.1-cp312-cp312-win_amd64.whl (150 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached wrapt-1.17.2-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: mpmath, cymem, wrapt, wasabi, typing-inspection, tqdm, threadpoolctl, sympy, spacy-loggers, spacy-legacy, shellingham, safetensors, regex, PyMuPDF, pydantic-core, Pillow, numpy, networkx, murmurhash, mdurl, marisa-trie, lxml, joblib, fsspec, filelock, cloudpathlib, click, catalogue, annotated-types, torch, srsly, smart-open, scipy, python-docx, pydantic, preshed, markdown-it-py, language-data, huggingface-hub, faiss-cpu, blis, tokenizers, scikit-learn, rich, langcodes, confection, typer, transformers, thinc, weasel, sentence-transformers, spacy\n",
      "Successfully installed Pillow-11.3.0 PyMuPDF-1.26.3 annotated-types-0.7.0 blis-1.3.0 catalogue-2.0.10 click-8.2.1 cloudpathlib-0.21.1 confection-0.1.5 cymem-2.0.11 faiss-cpu-1.11.0 filelock-3.18.0 fsspec-2025.5.1 huggingface-hub-0.33.2 joblib-1.5.1 langcodes-3.5.0 language-data-1.3.0 lxml-6.0.0 marisa-trie-1.2.1 markdown-it-py-3.0.0 mdurl-0.1.2 mpmath-1.3.0 murmurhash-1.0.13 networkx-3.5 numpy-2.3.1 preshed-3.0.10 pydantic-2.11.7 pydantic-core-2.33.2 python-docx-1.2.0 regex-2024.11.6 rich-14.0.0 safetensors-0.5.3 scikit-learn-1.7.0 scipy-1.16.0 sentence-transformers-5.0.0 shellingham-1.5.4 smart-open-7.3.0.post1 spacy-3.8.7 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 sympy-1.14.0 thinc-8.3.6 threadpoolctl-3.6.0 tokenizers-0.21.2 torch-2.7.1 tqdm-4.67.1 transformers-4.53.1 typer-0.16.0 typing-inspection-0.4.1 wasabi-1.1.3 weasel-0.4.1 wrapt-1.17.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.3/12.8 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.8/12.8 MB 2.2 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 1.0/12.8 MB 2.2 MB/s eta 0:00:06\n",
      "     ---- ----------------------------------- 1.3/12.8 MB 1.6 MB/s eta 0:00:08\n",
      "     ---- ----------------------------------- 1.6/12.8 MB 1.5 MB/s eta 0:00:08\n",
      "     ----- ---------------------------------- 1.8/12.8 MB 1.4 MB/s eta 0:00:08\n",
      "     ----- ---------------------------------- 1.8/12.8 MB 1.4 MB/s eta 0:00:08\n",
      "     ------ --------------------------------- 2.1/12.8 MB 1.4 MB/s eta 0:00:08\n",
      "     ------- -------------------------------- 2.4/12.8 MB 1.3 MB/s eta 0:00:09\n",
      "     -------- ------------------------------- 2.6/12.8 MB 1.3 MB/s eta 0:00:08\n",
      "     --------- ------------------------------ 2.9/12.8 MB 1.2 MB/s eta 0:00:09\n",
      "     --------- ------------------------------ 3.1/12.8 MB 1.2 MB/s eta 0:00:08\n",
      "     ---------- ----------------------------- 3.4/12.8 MB 1.3 MB/s eta 0:00:08\n",
      "     ----------- ---------------------------- 3.7/12.8 MB 1.2 MB/s eta 0:00:08\n",
      "     ------------ --------------------------- 3.9/12.8 MB 1.3 MB/s eta 0:00:07\n",
      "     ------------- -------------------------- 4.2/12.8 MB 1.3 MB/s eta 0:00:07\n",
      "     ------------- -------------------------- 4.5/12.8 MB 1.3 MB/s eta 0:00:07\n",
      "     -------------- ------------------------- 4.7/12.8 MB 1.3 MB/s eta 0:00:07\n",
      "     --------------- ------------------------ 5.0/12.8 MB 1.3 MB/s eta 0:00:07\n",
      "     ---------------- ----------------------- 5.2/12.8 MB 1.3 MB/s eta 0:00:06\n",
      "     ----------------- ---------------------- 5.5/12.8 MB 1.2 MB/s eta 0:00:06\n",
      "     ------------------ --------------------- 5.8/12.8 MB 1.2 MB/s eta 0:00:06\n",
      "     ------------------ --------------------- 6.0/12.8 MB 1.2 MB/s eta 0:00:06\n",
      "     ------------------ --------------------- 6.0/12.8 MB 1.2 MB/s eta 0:00:06\n",
      "     ------------------- -------------------- 6.3/12.8 MB 1.2 MB/s eta 0:00:06\n",
      "     -------------------- ------------------- 6.6/12.8 MB 1.2 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 6.8/12.8 MB 1.2 MB/s eta 0:00:05\n",
      "     --------------------- ------------------ 6.8/12.8 MB 1.2 MB/s eta 0:00:05\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 1.2 MB/s eta 0:00:05\n",
      "     ---------------------- ----------------- 7.3/12.8 MB 1.2 MB/s eta 0:00:05\n",
      "     ----------------------- ---------------- 7.6/12.8 MB 1.2 MB/s eta 0:00:05\n",
      "     ------------------------ --------------- 7.9/12.8 MB 1.2 MB/s eta 0:00:05\n",
      "     ------------------------- -------------- 8.1/12.8 MB 1.2 MB/s eta 0:00:05\n",
      "     -------------------------- ------------- 8.4/12.8 MB 1.2 MB/s eta 0:00:04\n",
      "     --------------------------- ------------ 8.7/12.8 MB 1.2 MB/s eta 0:00:04\n",
      "     --------------------------- ------------ 8.7/12.8 MB 1.2 MB/s eta 0:00:04\n",
      "     --------------------------- ------------ 8.9/12.8 MB 1.2 MB/s eta 0:00:04\n",
      "     ----------------------------- ---------- 9.4/12.8 MB 1.2 MB/s eta 0:00:03\n",
      "     ----------------------------- ---------- 9.4/12.8 MB 1.2 MB/s eta 0:00:03\n",
      "     ----------------------------- ---------- 9.4/12.8 MB 1.2 MB/s eta 0:00:03\n",
      "     ----------------------------- ---------- 9.4/12.8 MB 1.2 MB/s eta 0:00:03\n",
      "     ----------------------------- ---------- 9.4/12.8 MB 1.2 MB/s eta 0:00:03\n",
      "     ----------------------------- ---------- 9.4/12.8 MB 1.2 MB/s eta 0:00:03\n",
      "     ------------------------------ --------- 9.7/12.8 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------ --------- 9.7/12.8 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------ --------- 9.7/12.8 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 10.0/12.8 MB 1.0 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 10.0/12.8 MB 1.0 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 10.0/12.8 MB 1.0 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 10.0/12.8 MB 1.0 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 10.0/12.8 MB 1.0 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 10.0/12.8 MB 1.0 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 10.0/12.8 MB 1.0 MB/s eta 0:00:03\n",
      "     ------------------------------ ------- 10.2/12.8 MB 899.2 kB/s eta 0:00:03\n",
      "     ------------------------------ ------- 10.2/12.8 MB 899.2 kB/s eta 0:00:03\n",
      "     ------------------------------ ------- 10.2/12.8 MB 899.2 kB/s eta 0:00:03\n",
      "     ------------------------------ ------- 10.2/12.8 MB 899.2 kB/s eta 0:00:03\n",
      "     ------------------------------ ------- 10.2/12.8 MB 899.2 kB/s eta 0:00:03\n",
      "     ------------------------------ ------- 10.2/12.8 MB 899.2 kB/s eta 0:00:03\n",
      "     ------------------------------ ------- 10.2/12.8 MB 899.2 kB/s eta 0:00:03\n",
      "     ------------------------------ ------- 10.2/12.8 MB 899.2 kB/s eta 0:00:03\n",
      "     ------------------------------ ------- 10.2/12.8 MB 899.2 kB/s eta 0:00:03\n",
      "     ------------------------------ ------- 10.2/12.8 MB 899.2 kB/s eta 0:00:03\n",
      "     ------------------------------ ------- 10.2/12.8 MB 899.2 kB/s eta 0:00:03\n",
      "     ------------------------------- ------ 10.5/12.8 MB 767.1 kB/s eta 0:00:04\n",
      "     ------------------------------- ------ 10.7/12.8 MB 765.2 kB/s eta 0:00:03\n",
      "     --------------------------------- ---- 11.3/12.8 MB 792.7 kB/s eta 0:00:02\n",
      "     ----------------------------------- -- 11.8/12.8 MB 817.5 kB/s eta 0:00:02\n",
      "     ------------------------------------ - 12.3/12.8 MB 841.6 kB/s eta 0:00:01\n",
      "     -------------------------------------  12.6/12.8 MB 847.9 kB/s eta 0:00:01\n",
      "     -------------------------------------- 12.8/12.8 MB 852.3 kB/s eta 0:00:00\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers scikit-learn spacy numpy faiss-cpu PyMuPDF python-docx\n",
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "590fdf2d-5fcd-45b7-9c79-b240972d9461",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    {\n",
    "        \"id\": \"doc1\",\n",
    "        \"title\": \"Income Tax Deduction\",\n",
    "        \"body\": \"Under section 80C, individuals can claim deductions for education expenses and housing loan payments.\",\n",
    "        \"law_type\": \"Income Tax Act\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc2\",\n",
    "        \"title\": \"GST on Textiles\",\n",
    "        \"body\": \"The GST rate for textile products is 5% as per Schedule I of the GST Act.\",\n",
    "        \"law_type\": \"GST Act\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc3\",\n",
    "        \"title\": \"Property Registration\",\n",
    "        \"body\": \"The process of property registration includes paying stamp duty and registering with the sub-registrar.\",\n",
    "        \"law_type\": \"Property Law\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc4\",\n",
    "        \"title\": \"Court Fee\",\n",
    "        \"body\": \"Court fee for civil cases is based on the value of the suit as per the Court Fees Act.\",\n",
    "        \"law_type\": \"Court Judgments\"\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38782908-6291-471b-b09a-9e0422dceb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Misogi\\Day18\\Rag-Pipeline\\Legal-Document\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "for doc in documents:\n",
    "    doc['embedding'] = model.encode(doc['body'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6282f70a-8382-4ed0-931a-3381784d4d17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87c2129d-bb90-4de7-aec8-46f890afc670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    return set(ent.text.lower() for ent in doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efb37ba4-e516-4552-b40e-0ea3b7e1c702",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    doc['entities'] = extract_entities(doc['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "172fa9ee-3822-49cb-a671-d4bb13a002ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'are', 'how', 'you'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text='how are you'\n",
    "ent=extract_entities(text)\n",
    "ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c29dd565-78df-400c-9336-a2754ff194f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Income tax deduction for education\"\n",
    "query_embedding = model.encode(query)\n",
    "query_entities = extract_entities(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5517c0b1-7079-4403-92a8-c85c55cba13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def cosine_ranking(query_emb, docs):\n",
    "    scores = [(doc, cosine_similarity([query_emb], [doc['embedding']])[0][0]) for doc in docs]\n",
    "    return sorted(scores, key=lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9fefa9a-a260-41cb-9881-9b082fde98a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "def euclidean_ranking(query_emb, docs):\n",
    "    scores = [(doc, -euclidean_distances([query_emb], [doc['embedding']])[0][0]) for doc in docs]\n",
    "    return sorted(scores, key=lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b8fed76-ac8c-48cb-9481-d0d4c48b5853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mmr_ranking(query_emb, docs, lambda_param=0.7, top_k=3):\n",
    "    selected = []\n",
    "    candidates = docs.copy()\n",
    "\n",
    "    while len(selected) < top_k and candidates:\n",
    "        scores = []\n",
    "        for doc in candidates:\n",
    "            sim_query = cosine_similarity([query_emb], [doc['embedding']])[0][0]\n",
    "            sim_redundancy = max([cosine_similarity([doc['embedding']], [d['embedding']])[0][0] for d in selected], default=0)\n",
    "            mmr_score = lambda_param * sim_query - (1 - lambda_param) * sim_redundancy\n",
    "            scores.append((doc, mmr_score))\n",
    "        doc_max = max(scores, key=lambda x: x[1])\n",
    "        selected.append(doc_max[0])\n",
    "        candidates.remove(doc_max[0])\n",
    "    return [(doc, cosine_similarity([query_emb], [doc['embedding']])[0][0]) for doc in selected]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60ad9134-a532-41f7-a361-ac0d8046bf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_ranking(query_emb, query_ents, docs, w_cos=0.6, w_ent=0.4):\n",
    "    results = []\n",
    "    for doc in docs:\n",
    "        cosine_score = cosine_similarity([query_emb], [doc['embedding']])[0][0]\n",
    "        entity_score = len(query_ents.intersection(doc['entities'])) / (len(query_ents.union(doc['entities'])) + 1e-5)\n",
    "        hybrid_score = w_cos * cosine_score + w_ent * entity_score\n",
    "        results.append((doc, hybrid_score))\n",
    "    return sorted(results, key=lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be6cbfbd-f0b2-45d9-8c7a-8f9966ac13c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Cosine Similarity Results:\n",
      "1. Income Tax Deduction (Income Tax Act) - Score: 0.6623\n",
      "2. Property Registration (Property Law) - Score: 0.0843\n",
      "3. GST on Textiles (GST Act) - Score: 0.0605\n",
      "\n",
      "🔍 Euclidean Distance Results:\n",
      "1. Income Tax Deduction (Income Tax Act) - Score: -0.8218\n",
      "2. Property Registration (Property Law) - Score: -1.3533\n",
      "3. GST on Textiles (GST Act) - Score: -1.3708\n",
      "\n",
      "🔍 MMR Results:\n",
      "1. Income Tax Deduction (Income Tax Act) - Score: 0.6623\n",
      "2. GST on Textiles (GST Act) - Score: 0.0605\n",
      "3. Property Registration (Property Law) - Score: 0.0843\n",
      "\n",
      "🔍 Hybrid Similarity Results:\n",
      "1. Income Tax Deduction (Income Tax Act) - Score: 0.4395\n",
      "2. GST on Textiles (GST Act) - Score: 0.0563\n",
      "3. Property Registration (Property Law) - Score: 0.0506\n"
     ]
    }
   ],
   "source": [
    "def display_results(method_name, ranked_docs):\n",
    "    print(f\"\\n🔍 {method_name} Results:\")\n",
    "    for i, (doc, score) in enumerate(ranked_docs[:3], 1):\n",
    "        print(f\"{i}. {doc['title']} ({doc['law_type']}) - Score: {score:.4f}\")\n",
    "\n",
    "display_results(\"Cosine Similarity\", cosine_ranking(query_embedding, documents))\n",
    "display_results(\"Euclidean Distance\", euclidean_ranking(query_embedding, documents))\n",
    "display_results(\"MMR\", mmr_ranking(query_embedding, documents))\n",
    "display_results(\"Hybrid Similarity\", hybrid_ranking(query_embedding, query_entities, documents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6953d8de-8bd6-4db1-a7cc-5ee7984093c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_precision(ranked_docs, relevant_ids, k=3):\n",
    "    top_k = [doc['id'] for doc, _ in ranked_docs[:k]]\n",
    "    return len(set(top_k).intersection(relevant_ids)) / k\n",
    "\n",
    "def evaluate_diversity(ranked_docs, k=3):\n",
    "    top_k_laws = [doc['law_type'] for doc, _ in ranked_docs[:k]]\n",
    "    return len(set(top_k_laws)) / k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c15ba39-a60d-4978-8c3e-80a7731a0249",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
